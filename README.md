# ğŸŒ™ ComfyUI Luna Collection

![Version](https://img.shields.io/badge/version-v2.3.0-blue.svg)
![Python](https://img.shields.io/badge/python-3.10+-green.svg)
![License](https://img.shields.io/badge/license-MIT-yellow.svg)

**A production-grade ComfyUI infrastructure for advanced model management, multi-workflow VRAM sharing, and high-throughput image generation.**

Luna Collection is a vertically integrated image generation stack designed for enterprise-scale workflows. It provides workflow-aware daemon architecture for intelligent model multiplexing, unified model routing for all architectures (SD1.5/SDXL/Flux/SD3/Z-IMAGE), transient LoRA caching for zero-reload workflows, hierarchical YAML wildcards, comprehensive prompt engineering tools, and deep integration with external tools.

---

## ğŸ“ Latest Updates (v2.3)

ğŸ¯ **IP-Adapter TRUE BATCHING Integration** - Revolutionary refinement system
- **IP-Adapter Structural Anchoring**: Proper visionâ†’attention injection via learned projections, not naive fusion
- **TRUE BATCHING Architecture**: Batch dimension preserved - Latent[i] sees Embed[i], no averaging
- **12Ã— Speed Improvement**: Semantic Detailer batches all detections in one sample call
- **6Ã— Speed Improvement**: Chess Refiner batches 13 even + 12 odd tiles in two passes
- **Per-Detection Uniqueness**: Each face/object gets its own unique CLIP-ViT anchor
- **Integrated Upscale Loader**: Prep Upscaler includes built-in upscale model selection (4x-UltraSharp recommended)
- **100% Pixel-Space Refinement**: Semantic Detailer and Chess Refiner work entirely on pixels (crops â†’ encode fresh â†’ refine â†’ decode â†’ paste)
- See [LUNA_PHILOSOPHY_SHIFT.md](LUNA_PHILOSOPHY_SHIFT.md) for architectural deep-dive

ğŸ¨ **Luna Semantic Detailer Suite** - Surgical pyramid-based refinement system
- **Native Canvas Downscale**: Variable variance correction (0.0-1.0) for soft draft generation, optional area conditioning downscale
- **Scaffold Upscaler**: GPU-accelerated Lanczos, edge-preserving + texture coherence for artifact-free upscaling
- **SAM3 Detector**: Semantic concept detection with pre-encoded conditioning, per-concept prompts, hierarchical layers
- **Semantic Detailer**: Per-detection IP-Adapter anchoring, 1024px crops, true batching, chainable multi-layer refinement
- **Chess Refiner**: Global tile refinement with IP-Adapter vision anchoring, chess pattern for seamless blending
- **Full daemon integration**: SAM3 runs on secondary GPU, shared CLIP encoding for multi-detection batching

âœ¨ **Luna Batch Upscale Refine** - Production-grade tiled upscaler with scaffolding noise + chess-pattern batching
- Auto-detect upscale factor (1x/2x/4x/8x/16x)
- Latent-space tiling for 64x smaller tensor operations
- Sigmoid blending mode + feathering control
- GPU Lanczos supersampling (e.g., refine 4x, output 2x)
- Tiled VAE decode prevents boundary artifacts

ğŸ¯ **FP8 Precision Expansion** - Now supports all three FP8 variants
- `fp8_e4m3fn` - RTX 40-series native (5090/4090)
- `fp8_e4m3fn_scaled` - RTX 40-series recommended
- `fp8_e5m2` - RTX 30-series better exponent range

ğŸ¦™ **Qwen3-VL GGUF Support** - Z-IMAGE now works with quantized GGUF models
- Uses patched llama-cpp-python fork
- Q8_0 for quality, Q4_K_M for efficiency
- Auto-detect format, mmproj auto-loads

---

## âœ¨ Key Features

### ğŸš€ **Workflow-Aware Multi-Instance Architecture**
- **Multi-Workflow Multiplexing**: Run multiple workflows simultaneously sharing CLIP/VAE models
- **Intelligent Model Routing**: Daemon tracks which models each workflow needs, sideloads new ones without unloading
- **Zero Redundancy**: Workflows sharing same VAE use one loaded instance, not duplicate copies
- **InferenceModeWrapper**: Automatic VRAM management for UNet models
- **Workflow Isolation**: Each workflow gets correct model set despite shared infrastructure

### ğŸ”§ **Core Infrastructure**
- **Luna Model Router**: Unified model loader for all architectures with explicit CLIP/VAE configuration
- **Luna Daemon v2.0**: Multi-workflow daemon with per-workflow model tracking and sideloading
- **Dynamic Precision Conversion**: JIT bf16/fp8/GGUF conversion with intelligent caching
- **Transient LoRA System**: LoRAs cached in RAM, applied with randomized weights, restored without disk I/O
- **Config Gateway**: Centralized workflow parameter management with LoRA weight caching
- **Reset Weights Node**: Ctrl-Z for LoRA modifications between workflow runs

### ğŸ“¦ **Model Management**
- **Unified Model Router**: Single node supporting SD1.5, SDXL, Flux, SD3, Z-IMAGE with vision variants
- **Smart Precision Loading**: bf16, fp8, GGUF Q8_0/Q4_K_M with automatic conversion and caching
- **Explicit CLIP/VAE Selection**: Dynamic selectors updated based on model_type
- **Precision Conversion Cache**: Converted models saved to correct directories (e.g., `unet/fp8/`)
- **InferenceModeWrapper**: UNet models wrapped for automatic VRAM management

### ğŸ² **Prompt Engineering**
- **YAML Wildcards**: Hierarchical templates with nested path resolution and inline substitution
- **LoRA Weight Randomization**: Same LoRAs, different random weights per run, no reload
- **Config Gateway Integration**: Automatic LoRA extraction from prompts, deduplication, caching
- **Prompt List Loader**: CSV/JSON/YAML import with pos/neg/seed/lora_stack outputs
- **Trigger Injector**: Auto-inject LoRA trigger words into prompts

### ğŸ–¼ï¸ **Image Processing**
- **Vision Node**: Image-to-embedding for vision-enabled model workflows
- **Advanced Upscaling**: Model-based, tile-based, and multi-stage upscaling
- **Ultimate SD Upscale**: Diffusion-enhanced upscaling with seam fixing
- **Multi-Image Saver**: Batch output with naming templates and EXIF embedding

---

## ğŸ—ï¸ Architecture v2.0

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          LUNA COLLECTION v2.0                                   â”‚
â”‚          "Multi-Workflow Image Generation Infrastructure"                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    WORKFLOW-AWARE DAEMON (Multi-Instance Multiplexing)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Luna Daemon v2.0 - Workflow Multiplexer                                        â”‚
â”‚                                                                                 â”‚
â”‚  workflow_model_sets = {                                                        â”‚
â”‚    "workflow_A": {models: {clip_l: path_A, clip_g: path_A, vae: path_shared}}  â”‚
â”‚    "workflow_B": {models: {clip_l: path_B, clip_g: path_B, vae: path_shared}}  â”‚
â”‚  }                                                                              â”‚
â”‚                                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Worker Pool (VAE)                                                      â”‚   â”‚
â”‚  â”‚  â€¢ Worker 1: vae_shared.safetensors (shared by A & B)                  â”‚   â”‚
â”‚  â”‚  â€¢ Routes VAE ops to correct worker based on workflow_id               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Worker Pool (CLIP)                                                     â”‚   â”‚
â”‚  â”‚  â€¢ Worker 1: clip_l_A, clip_g_A                                        â”‚   â”‚
â”‚  â”‚  â€¢ Worker 2: clip_l_B, clip_g_B                                        â”‚   â”‚
â”‚  â”‚  â€¢ Routes CLIP ops to correct worker based on workflow_id              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                 â”‚
â”‚  Benefits:                                                                      â”‚
â”‚  â€¢ No model unloading - all models stay loaded                                 â”‚
â”‚  â€¢ Shared models reused across workflows (VAE example above)                   â”‚
â”‚  â€¢ New workflows trigger sideloading, not replacement                          â”‚
â”‚  â€¢ Intelligent routing ensures correct models per workflow                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                              MODEL ROUTER & LOADING
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Luna Model Router âš¡      â”‚  â”‚  InferenceModeWrapper      â”‚
â”‚  â”œâ”€â”€ All architectures     â”‚  â”‚  â”œâ”€â”€ Auto VRAM management  â”‚
â”‚  â”œâ”€â”€ SD1.5/SDXL/Flux/SD3   â”‚  â”‚  â”œâ”€â”€ Wraps loaded UNet     â”‚
â”‚  â”œâ”€â”€ Z-IMAGE + Vision      â”‚  â”‚  â”œâ”€â”€ Lazy loading support  â”‚
â”‚  â”œâ”€â”€ Dynamic CLIP selectorsâ”‚  â”‚  â””â”€â”€ Transparent to nodes  â”‚
â”‚  â”œâ”€â”€ Precision conversion  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  â””â”€â”€ Daemon proxy creation â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Flow: Router â†’ Precision Convert â†’ InferenceModeWrapper â†’ Daemon Proxies

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                          TRANSIENT LORA SYSTEM (Zero-Reload Workflow)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Config Gateway                           Reset Weights Node                    â”‚
â”‚  â”œâ”€â”€ Cache pristine weights (affected     â”œâ”€â”€ Restore cached weights           â”‚
â”‚  â”‚   layers only, ~5-10% of model)        â”œâ”€â”€ Clear cache                      â”‚
â”‚  â”œâ”€â”€ Apply LoRAs with random weights      â””â”€â”€ Prepare for next run             â”‚
â”‚  â””â”€â”€ LoRAs stay in RAM (daemon cache)                                          â”‚
â”‚                                                                                 â”‚
â”‚  Workflow Run 1:                          Workflow Run 2:                       â”‚
â”‚  â€¢ Cache weights                          â€¢ Restore from cache                 â”‚
â”‚  â€¢ Apply lora_1@0.75, lora_2@1.2         â€¢ Apply lora_1@0.42, lora_2@0.88    â”‚
â”‚  â€¢ Inference                              â€¢ Inference                          â”‚
â”‚  â€¢ Reset â†’ pristine state                 â€¢ Reset â†’ pristine state             â”‚
â”‚                                                                                 â”‚
â”‚  Benefits:                                                                      â”‚
â”‚  â€¢ No disk I/O between runs (LoRAs cached in RAM)                             â”‚
â”‚  â€¢ No precision drift (exact clone restoration)                                â”‚
â”‚  â€¢ Supports randomized LoRA weights per run                                    â”‚
â”‚  â€¢ Minimal memory overhead (only affected layers cached)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                              PROMPT ENGINEERING
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Luna YAML Wildcard        â”‚  â”‚  Luna Config Gateway       â”‚
â”‚  â”œâ”€â”€ {file:path.to.items}  â”‚  â”‚  â”œâ”€â”€ Auto LoRA extraction  â”‚
â”‚  â”œâ”€â”€ [inline.substitution] â”‚  â”‚  â”œâ”€â”€ LoRA deduplication    â”‚
â”‚  â”œâ”€â”€ {1-10} numeric ranges â”‚  â”‚  â”œâ”€â”€ Weight caching        â”‚
â”‚  â””â”€â”€ __legacy/txt__ compat â”‚  â”‚  â””â”€â”€ Centralized params    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¨ Luna Semantic Detailer Suite

**A hierarchical, multi-pass refinement system for surgical image enhancement.** Replaces blind tiled upscaling with semantic-aware pyramidal refinement.

### ğŸ—ï¸ Workflow Architecture

```
1. Pyramid Noise Generator
   â”œâ”€ Model-aware (SDXL, SD1.5, Flux)
   â”œâ”€ Aspect ratio selection (1:1, 16:9, 3:2, etc.)
   â”œâ”€ Outputs: full_scaffold (4K), draft_scaffold (1K)
   â””â”€ Variance correction: Ïƒ=1.0 preserved at all scales

2. Draft Generation
   â”œâ”€ KSampler on draft_scaffold (1K fast)
   â”œâ”€ VAE decode to pixels (1K neutral image)
   â””â”€ Input to detector for fast analysis

3. Scaffold Upscaler
   â”œâ”€ Lanczos GPU-accelerated upscale (no upscale model)
   â”œâ”€ Edge preservation + texture coherence
   â”œâ”€ Creates neutral 4K canvas (no AI artifacts)
   â””â”€ Outputs: upscaled_pixels (4K), full_scaffold_passthrough

4. SAM3 Detector
   â”œâ”€ Detects objects on 1K draft (fast)
   â”œâ”€ Per-concept prompts (face, eye, hand, etc.)
   â”œâ”€ Hierarchical layers (0=structural, 1+=details)
   â”œâ”€ Encodes prompts with CLIP upfront
   â””â”€ Outputs: LUNA_DETECTION_PIPE (coordinates + conditioning)

5. Semantic Detailer (Chainable, Multi-Layer)
   â”œâ”€ Extracts crops from 4K canvas
   â”œâ”€ Refinement at 1024Ã—1024 (optimal for SDXL/Flux)
   â”œâ”€ Batched sampling with per-concept conditioning
   â”œâ”€ Supports enlarge_crops for small inputs
   â”œâ”€ Outputs: refined_image + refined_latent + detection_pipe (passthrough)
   â””â”€ Chaining: Layer 0 â†’ Layer 1 â†’ Layer 2 (cumulative refinement)

6. Chess Refiner (Final Global Pass)
   â”œâ”€ Chess-pattern tiling (even/odd for seamless blending)
   â”œâ”€ Uses full_scaffold for 1:1 noise density
   â”œâ”€ Optional supersampling (0.25-1.0x scale)
   â”œâ”€ Smoothstep blending (invisible seams)
   â””â”€ Outputs: final_image (2K supersampled)
```

### ğŸ”¬ Key Mathematical Principles

**Variance Preservation:**
```
When downscaling noise: Ïƒ_new = Ïƒ_original / scale_factor
Solution: Multiply by scale_factor to restore Ïƒ = 1.0
Example: 4Kâ†’1K (4x) = multiply by 4.0
```

**1024px Standard:**
- SDXL native training resolution
- Optimal for anatomical features
- True GPU batch processing

**Smoothstep Blending:**
- Polynomial: tÂ²(3-2t)
- CÂ¹ continuity (no visible seams)
- Better than linear alpha blending

### ğŸ’¡ Use Cases

**Pyramid Workflow (4K Refinement):**
```
Pyramid Noise (4K) â†’ Draft (1K) â†’ Scaffold Up (4K)
â†’ Detect â†’ Semantic Detailer (surgical) â†’ Chess (global) â†’ 2K output
```
âœ… Maximum quality  
âœ… True 1:1 noise preservation  
âœ… Multi-layer specialization possible

**Traditional Workflow (1K Base):**
```
1K image â†’ batch_upscale_refine (4x to 4K)
â†’ Semantic Detailer (enlarge_crops=True) â†’ Final output
```
âœ… Compatible with existing workflows  
âœ… Uses same detailer nodes  
âœ… Upscales detected regions

**Layered LoRA Refinement:**
```
Base generation (1:1)
â†’ Detailer Layer 0 + face_lora (detailed faces)
â†’ Detailer Layer 1 + eye_lora (iris details)
â†’ Detailer Layer 2 + clothing_lora (fabric texture)
â†’ Chess Refiner (global coherence)
```
âœ… Each layer specializes  
âœ… Per-layer conditioning  
âœ… No quality degradation from multi-pass

---

## ğŸš€ Installation

### Prerequisites
- ComfyUI (latest version recommended)
- Python 3.10+
- PyTorch with CUDA support
- (Optional) Multi-GPU setup for daemon architecture

### Quick Install
```bash
cd ComfyUI/custom_nodes/
git clone https://github.com/LSDJesus/ComfyUI-Luna-Collection.git
cd ComfyUI-Luna-Collection
pip install -r requirements.txt
```

Restart ComfyUI. Nodes appear under **`Luna/`** categories.

---

## ğŸ¯ Core Workflows

### Single Workflow with Precision Conversion

```
[Luna Model Router]
  â”œâ”€ model_source: checkpoints
  â”œâ”€ model_name: illustriousXL.safetensors
  â”œâ”€ model_type: SDXL
  â”œâ”€ dynamic_precision: fp8_e4m3fn
  â”œâ”€ clip_1: clip_l.safetensors
  â”œâ”€ clip_2: clip_g.safetensors
  â””â”€ vae_name: sdxl_vae.safetensors
       â†“
  OUTPUT: MODEL (InferenceModeWrapper), CLIP, VAE
       â†“
[Config Gateway] â†’ [KSampler] â†’ [Reset Weights]
```

### Multi-Workflow Daemon Setup

**Instance A** (Port 8188):
```
[Model Router] 
  â”œâ”€ SDXL + clip_l_A, clip_g_A, vae_shared
  â””â”€ daemon_mode: auto
       â†“
  Daemon receives: workflow_id="A", models={clip_l: path_A, ...}
  Daemon creates: Worker 1 (clip_A), Worker 3 (vae_shared)
```

**Instance B** (Port 8189):
```
[Model Router]
  â”œâ”€ SDXL + clip_l_B, clip_g_B, vae_shared  
  â””â”€ daemon_mode: auto
       â†“
  Daemon receives: workflow_id="B", models={clip_l: path_B, ...}
  Daemon sideloads: Worker 2 (clip_B), reuses Worker 3 (vae_shared)
```

Both workflows share VAE, each has own CLIP, no model unloading.

### High-Throughput Random Generation

```
[Model Router] â†’ [Config Gateway] â†’ [YAML Wildcard]
                      â†“                    â†“
                 Cache weights        Random prompts
                 Extract LoRAs        Random LoRA weights
                      â†“
                 [KSampler] â†’ [Save Image] â†’ [Reset Weights]
                                                  â†“
                                            Restore pristine
                                            Ready for next run
```

Run 2000+ times/day with same 6-7 LoRAs, different random weights each time, zero disk I/O.

---

## ğŸ“¦ Node Reference

### ğŸ”§ **Model Loading**

| Node | Description |
|------|-------------|
| **Luna Model Router âš¡** | Unified loader for all architectures with dynamic CLIP/VAE selectors and precision conversion |
| **Luna Dynamic Model Loader** | Legacy smart checkpoint loading (use Model Router instead) |
| **Luna GGUF Converter** | Convert checkpoints to quantized GGUF format |

**Model Router Outputs:**
- `MODEL` - UNet wrapped in InferenceModeWrapper (or DaemonModel if daemon enabled)
- `CLIP` - DaemonCLIP proxy (routes to daemon) or local CLIP
- `VAE` - DaemonVAE proxy (routes to daemon) or local VAE
- `LLM` - Full LLM for Z-IMAGE (Qwen3-VL)
- `CLIP_VISION` - Vision encoder for vision model types
- `model_name` - String for Config Gateway
- `status` - Detailed loading status

### ğŸŒ **Luna Daemon (Multi-Workflow Architecture)**

Daemon now uses workflow-aware multiplexing - each workflow gets its own model set, shared models are reused.

| Node | Description |
|------|-------------|
| **Luna Daemon Status** | Check daemon connection and loaded workflow model sets |

**Starting the Daemon:**
```bash
# Start daemon server
python luna_daemon/daemon_server.py

# Or use PowerShell script
.\scripts\start_daemon.ps1
```

**Client API (used by proxies):**
```python
# Request models for a workflow
daemon_client.get_model_proxies(
    workflow_id="my_workflow_123",  # Unique per ComfyUI instance
    model_type="SDXL",
    models={
        "clip_l": "/path/to/clip_l.safetensors",
        "clip_g": "/path/to/clip_g.safetensors",
        "vae": "/path/to/vae.safetensors"
    }
)

# All subsequent CLIP/VAE ops include workflow_id
daemon_client.clip_encode("prompt", workflow_id="my_workflow_123")
daemon_client.vae_decode(latents, workflow_id="my_workflow_123")
```

### ğŸ² **Workflow Management**

| Node | Description |
|------|-------------|
| **Luna Config Gateway** | Centralized workflow parameters with LoRA weight caching |
| **Luna Reset Model Weights** | Restore model to pristine state after LoRA application |

**Config Gateway Features:**
- Auto-extracts LoRAs from prompts (`<lora:name:weight>` syntax)
- Deduplicates with lora_stack input
- Caches pristine weights before LoRA application
- Applies LoRAs with specified (or randomized) weights
- Outputs complete workflow config for image EXIF

**Reset Weights Node:**
- Place at end of workflow
- Restores cached weights (no disk I/O, no precision drift)
- Clears cache to free memory
- Prepares model for next run with different LoRA weights
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   GPU 0 (cuda:0)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚           VAE Daemon (:19284)                    â”‚   â”‚
â”‚  â”‚  â€¢ Same GPU as UNet = CUDA IPC zero-copy        â”‚   â”‚
â”‚  â”‚  â€¢ No socket serialization overhead             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  ComfyUI Instances (UNet only)                  â”‚   â”‚
â”‚  â”‚  :8188, :8189, :8190...                         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Starting the Daemon:**
```bash
# Full daemon (CLIP + VAE on one GPU)
python luna_daemon/server.py

# Split mode - CLIP on cuda:1
python luna_daemon/server.py --service-type clip --device cuda:1 --port 19283

# Split mode - VAE on cuda:0 with IPC
python luna_daemon/server.py --service-type vae --device cuda:0 --port 19284
```

### ğŸ“¦ **Model Management**

| Node | Description |
|------|-------------|
| **Luna Model Router âš¡** | Unified loader for all architectures (SD1.5/SDXL/Flux/SD3/Z-IMAGE) with explicit CLIP config |
| **Luna Secondary Model Loader ğŸ”„** | Multi-model workflows with CLIP sharing and RAM offloading |
| **Luna Model Restore ğŸ“¤** | Restore models offloaded to RAM back to VRAM |
| **Luna Dynamic Model Loader** | Smart checkpoint loading with JIT precision conversion |
| **Luna Checkpoint Tunnel** | Pass MODEL through, route CLIP/VAE to daemon |
| **Luna GGUF Converter** | Convert checkpoints to quantized GGUF format |
| **Luna Optimized Weights Manager** | Manage local optimized UNet files |

**Luna Model Router** - The unified model loader:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Luna Model Router âš¡                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  MODEL SOURCE:     [checkpoints â–¼] [diffusion_models â–¼] [unet (gguf) â–¼]    â”‚
â”‚  MODEL NAME:       [ponyDiffusionV6XL.safetensors â–¼]                       â”‚
â”‚  MODEL TYPE:       [SD1.5] [SDXL] [SDXL+Vision] [Flux] [Flux+Vision] [SD3] [Z-IMAGE] â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  DYNAMIC LOADER:   [âœ“ Enable] â†’ [fp8_e4m3fn â–¼] [gguf_Q8_0 â–¼]               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  CLIP 1:          [clip_l.safetensors â–¼]     â† Required for all           â”‚
â”‚  CLIP 2:          [clip_g.safetensors â–¼]     â† SDXL, SD3                   â”‚
â”‚  CLIP 3:          [t5xxl_fp16.safetensors â–¼] â† Flux, SD3                   â”‚
â”‚  CLIP 4:          [siglip_vision.safetensors â–¼] â† Vision models            â”‚
â”‚                                                                             â”‚
â”‚  Z-IMAGE: clip_1 = Full Qwen3-VL model (hidden state extraction)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  OUTPUTS: MODEL, CLIP, VAE, LLM, CLIP_VISION, model_name, status           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**CLIP Requirements by Model Type:**
| Model Type | clip_1 | clip_2 | clip_3 | clip_4 |
|------------|--------|--------|--------|--------|
| SD1.5 | CLIP-L | - | - | - |
| SDXL | CLIP-L | CLIP-G | - | - |
| SDXL + Vision | CLIP-L | CLIP-G | - | SigLIP/CLIP-H |
| Flux | CLIP-L | - | T5-XXL | - |
| Flux + Vision | CLIP-L | - | T5-XXL | SigLIP |
| SD3 | CLIP-L | CLIP-G | T5-XXL | - |
| Z-IMAGE | Full Qwen3-VL | - | - | (auto mmproj) |

**Luna Dynamic Model Loader** - The smart precision loader:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             8TB HDD (Source Library)                   â”‚
â”‚  358 FP16 Checkpoints (6.5GB each)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼ First use: extract UNet + convert
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             NVMe (Local Optimized Weights)             â”‚
â”‚  models/unet/optimized/                                â”‚
â”‚  â€¢ illustriousXL_Q8_0.gguf (3.2GB)                     â”‚
â”‚  â€¢ ponyV6_fp8_e4m3fn_unet.safetensors (2.1GB)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼ Smart lazy evaluation
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â€¢ MODEL always loads optimized UNet                   â”‚
â”‚  â€¢ CLIP/VAE only load if outputs are connected         â”‚
â”‚  â€¢ No mode selection needed - just wire what you need  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Supported Precisions:**
| Precision | Best For | Size Reduction |
|-----------|----------|----------------|
| `bf16` | Universal, fast | ~50% |
| `fp8_e4m3fn` | Ada/Blackwell GPUs | ~75% |
| `gguf_Q8_0` | Ampere INT8 tensor cores | ~50% |
| `gguf_Q4_K_M` | Blackwell INT4 tensor cores | ~75% |

### ğŸ² **YAML Wildcards**

| Node | Description |
|------|-------------|
| **Luna YAML Wildcard** | Hierarchical wildcard expansion |
| **Luna YAML Wildcard Batch** | Generate multiple prompts with seeds |
| **Luna Wildcard Builder** | Visual prompt composition |
| **Luna LoRA Randomizer** | Random LoRA selection from YAML |

**Prompt Syntax:**
```
{filename}                    â†’ Random template from templates section
{filename:path.to.items}      â†’ Random item from nested path
{filename: text [path.sub]}   â†’ Inline template with substitutions
{1-10}                        â†’ Random integer
{0.5-1.5:0.1}                 â†’ Random float with step
__path/file__                 â†’ Legacy .txt wildcard
```

**Example YAML (`models/wildcards/characters.yaml`):**
```yaml
templates:
  hero:
    - "a [appearance.build] [species.humanoid] with [features.eyes]"
    
appearance:
  build:
    - muscular
    - slender
    - athletic
    
species:
  humanoid:
    - elf
    - human
    - tiefling
    
features:
  eyes:
    - glowing blue eyes
    - heterochromatic eyes
```

### ğŸ² **YAML Wildcards**

| Node | Description |
|------|-------------|
| **Luna YAML Wildcard** | Hierarchical wildcard expansion with templates and nested paths |
| **Luna YAML Wildcard Batch** | Generate multiple prompts with seeds for batch workflows |
| **Luna Wildcard Builder** | Visual prompt composition with real-time preview |
| **Luna LoRA Randomizer** | Random LoRA selection from YAML files with weight control |

**Prompt Syntax:**
```
{filename}                    â†’ Random template from templates section
{filename:path.to.items}      â†’ Random item from nested path
{filename: text [path.sub]}   â†’ Inline template with [path] substitutions
{1-10}                        â†’ Random integer range
{0.5-1.5:0.1}                 â†’ Random float with step resolution
__path/file__                 â†’ Legacy .txt wildcard (recursive)
```

**Example YAML** (`models/wildcards/characters.yaml`):
```yaml
templates:
  hero:
    - "a [appearance.build] [species.humanoid] with [features.eyes]"
    - "[species.humanoid] [appearance.build] character, [features.eyes]"
    
appearance:
  build: [muscular, slender, athletic, stocky]
    
species:
  humanoid: [elf, human, tiefling, dwarf]
    
features:
  eyes:
    - glowing blue eyes
    - heterochromatic eyes
    - emerald eyes
```

**Usage in Prompt:**
```
{characters:hero} warrior in armor
â†’ "a muscular elf with glowing blue eyes warrior in armor"
```

---

## ğŸ”„ Migration from v1.x

### Key Changes in v2.0

**Daemon Architecture:**
- Old: Split CLIP/VAE daemons on separate GPUs
- New: Unified daemon with workflow-aware multiplexing
- Migration: Update daemon startup scripts, remove split config

**Model Loading:**
- Old: Dynamic Model Loader with lazy evaluation
- New: Model Router handles everything (precision, CLIP, VAE, daemon)
- Migration: Replace Dynamic Loader nodes with Model Router

**LoRA System:**
- Old: Manual LoRA loading, reload from disk each run
- New: Transient LoRA caching, weight restoration via Reset node
- Migration: Add Reset Weights node at end of workflows

**Config Gateway:**
- Old: Basic parameter passing
- New: LoRA weight caching, automatic extraction/deduplication
- Migration: No changes needed, just benefits from new features

---

## ğŸ’¡ Use Cases

### High-Throughput Random Generation
**Scenario**: Generate 2000+ images/day with randomized prompts and LoRA weights

```
Workflow Setup:
â”œâ”€ [Model Router] â†’ Load finetuned Illustrious model with fp8 precision
â”œâ”€ [Config Gateway] â†’ Extract 6-7 LoRAs from prompt (same set each run)
â”œâ”€ [YAML Wildcard] â†’ Random prompts with {character}, {pose}, {background}
â”œâ”€ [Random LoRA Weights] â†’ Randomize strengths (0.5-1.5) each run
â”œâ”€ [KSampler] â†’ Generate image
â””â”€ [Reset Weights] â†’ Restore model to pristine state

Benefits:
â€¢ LoRAs cached in RAM after first load (zero disk I/O)
â€¢ Model weights cached before LoRA application
â€¢ Each run: restore cache â†’ apply random weights â†’ infer â†’ reset
â€¢ Time saved: ~1 second per workflow Ã— 2000 runs = 33 minutes/day
```

### Multi-Workflow Production Setup
**Scenario**: Multiple ComfyUI instances running different workflows simultaneously

```
Instance A (Port 8188) - Character Generation:
â”œâ”€ Model: characterMix_SDXL
â”œâ”€ CLIP: clip_l_custom, clip_g_custom
â”œâ”€ VAE: sdxl_vae (shared)
â””â”€ Daemon: workflow_id="char_gen"

Instance B (Port 8189) - Background Generation:
â”œâ”€ Model: landscapeMix_SDXL  
â”œâ”€ CLIP: clip_l_standard, clip_g_standard
â”œâ”€ VAE: sdxl_vae (shared - reused from A!)
â””â”€ Daemon: workflow_id="bg_gen"

Instance C (Port 8190) - Testing/Development:
â”œâ”€ Model: testMix_SDXL
â”œâ”€ CLIP: clip_l_custom (reused from A!)
â”œâ”€ VAE: sdxl_vae (shared - reused from A!)
â””â”€ Daemon: workflow_id="testing"

Daemon State:
â€¢ 5 total CLIPs loaded (clip_l_custom, clip_g_custom, clip_l_std, clip_g_std)
â€¢ 1 VAE loaded (shared by all 3 instances)
â€¢ No model unloading - all stay resident
â€¢ Intelligent routing ensures each workflow uses correct models
```

### Precision Conversion Pipeline
**Scenario**: Convert checkpoint library to optimized formats for faster loading

```
Step 1: Batch convert checkpoints to fp8
â”œâ”€ [Model Router] â†’ Load checkpoint.safetensors
â”œâ”€ dynamic_precision: fp8_e4m3fn
â””â”€ First load triggers conversion â†’ saves to unet/fp8/checkpoint_unet.safetensors

Step 2: Subsequent loads are instant
â”œâ”€ [Model Router] â†’ Same checkpoint
â”œâ”€ dynamic_precision: fp8_e4m3fn  
â””â”€ Finds existing fp8 file â†’ loads directly (no conversion)

Result:
â€¢ 6.5GB checkpoint â†’ 2.1GB fp8 file
â€¢ First load: 45 seconds (load + convert + save)
â€¢ Subsequent loads: 8 seconds (direct load)
â€¢ 80% VRAM savings
```

---

## ğŸ› ï¸ Advanced Configuration

### Daemon Configuration (`luna_daemon/config.py`)

```python
# Network settings
DAEMON_HOST = "127.0.0.1"
DAEMON_PORT = 19283

# Worker pool sizing
MIN_VAE_WORKERS = 1
MAX_VAE_WORKERS = 2
MIN_CLIP_WORKERS = 1
MAX_CLIP_WORKERS = 2

# Model precision
VAE_PRECISION = "fp32"  # or "fp16", "bf16"
CLIP_PRECISION = "fp32"

# Device assignment
VAE_DEVICE = "cuda:0"
CLIP_DEVICE = "cuda:1"  # Use separate GPU for CLIP if available
```

### Model Router Dynamic Selectors

CLIP/VAE selectors update automatically based on `model_type`:

| Model Type | clip_1 | clip_2 | clip_3 | clip_4 | vae |
|------------|--------|--------|--------|--------|-----|
| SD1.5 | CLIP-L only | disabled | disabled | disabled | SD VAE |
| SDXL | CLIP-L | CLIP-G | disabled | disabled | SDXL VAE |
| Flux | CLIP-L | disabled | T5-XXL | disabled | Flux VAE |
| SD3 | CLIP-L | CLIP-G | T5-XXL | disabled | SD3 VAE |
| Z-IMAGE | Qwen3-VL (full) | disabled | disabled | mmproj (auto) | Any VAE |

**Z-IMAGE + Qwen3-VL GGUF Support (NEW in v2.1):**

Z-IMAGE now supports GGUF-quantized Qwen3-VL models via patched [llama-cpp-python](https://github.com/JamePeng/llama-cpp-python):

```bash
# Install the fork with Qwen3-VL support
pip install git+https://github.com/JamePeng/llama-cpp-python

# Then use GGUF Qwen3-VL models directly in Model Router
# The daemon auto-detects format and routes through llama-cpp-python
```

**Qwen3-VL Format Options:**
- `.safetensors` (HuggingFace) - Full precision, large VRAM
- `.gguf` (GGUF quantized) - Q8_0 for quality, Q4_K_M for efficiency
- Auto-detection: Model Router checks file extension and loads appropriately
- mmproj auto-loads if in same folder as model (for vision support)

### Precision Conversion Targets

Converted models are saved to precision-specific directories:

```
models/
â”œâ”€â”€ checkpoints/
â”‚   â””â”€â”€ illustriousXL.safetensors (6.5GB source)
â”œâ”€â”€ unet/
â”‚   â”œâ”€â”€ fp8/
â”‚   â”‚   â”œâ”€â”€ illustriousXL_unet_fp8_e4m3fn.safetensors (2.1GB)
â”‚   â”‚   â”œâ”€â”€ illustriousXL_unet_fp8_e4m3fn_scaled.safetensors (2.1GB)
â”‚   â”‚   â””â”€â”€ illustriousXL_unet_fp8_e5m2.safetensors (2.1GB)
â”‚   â”œâ”€â”€ gguf/
â”‚   â”‚   â”œâ”€â”€ illustriousXL_Q8_0.gguf (3.2GB)
â”‚   â”‚   â””â”€â”€ illustriousXL_Q4_K_M.gguf (1.8GB)
â”‚   â””â”€â”€ bf16/
â”‚       â””â”€â”€ illustriousXL_unet.safetensors (3.3GB)
```

**Precision Options by Hardware:**
- **RTX 40-series (5090/4090)**: Use `fp8_e4m3fn` or `fp8_e4m3fn_scaled` for native hardware acceleration
- **RTX 40-series (RTX 5090)**: `fp8_e4m3fn_scaled` recommended for best quality
- **RTX 30-series (3090/3080Ti)**: Use `fp8_e5m2` (better exponent range) or `gguf_Q8_0` (best quality)
- **All GPUs**: `gguf_Q8_0` provides quality closest to FP16 with efficient VRAM usage

---

## ğŸ“Š Performance Benchmarks

### LoRA Loading Performance

| Method | First Load | Subsequent Loads | Memory Overhead |
|--------|-----------|------------------|-----------------|
| **Traditional** (reload from disk) | 800ms | 800ms | 0MB |
| **Luna Transient Cache** | 850ms | 50ms | ~200MB for 7 LoRAs |

Savings over 2000 runs: (800ms - 50ms) Ã— 2000 = **25 minutes saved**

### Precision Conversion Impact

| Format | Size | VRAM | Load Time | Inference Speed | Hardware |
|--------|------|------|-----------|-----------------|----------|
| FP16 (baseline) | 6.5GB | 6.5GB | 12s | 1.0Ã— | All |
| BF16 | 6.5GB | 6.5GB | 12s | 1.0Ã— | All |
| FP8 E4M3FN | 3.3GB | 3.3GB | 8s | 0.97Ã— | RTX 40+ |
| FP8 E4M3FN Scaled | 3.3GB | 3.3GB | 8s | 0.98Ã— | RTX 40+ (recommended) |
| FP8 E5M2 | 3.3GB | 3.3GB | 8s | 0.96Ã— | RTX 30/20 (better range) |
| GGUF Q8_0 | 3.2GB | 3.2GB | 9s | 0.92Ã— | All (best quality) |
| GGUF Q4_K_M | 1.8GB | 1.8GB | 7s | 0.80Ã— | All (aggressive compression) |

### Multi-Workflow VRAM Sharing

| Setup | Total VRAM | Without Daemon | With Daemon | Savings |
|-------|-----------|----------------|-------------|---------|
| 3 instances, same VAE/CLIP | 24GB | 18GB (3Ã—6GB) | 8GB (1Ã—6GB + 2Ã—1GB UNet) | 55% |
| 3 instances, different CLIP, same VAE | 24GB | 22GB | 12GB | 45% |

---

## ğŸ› Troubleshooting

### Daemon Not Connecting
```
Error: "Daemon not running" in Model Router

Solutions:
1. Start daemon: python luna_daemon/daemon_server.py
2. Check port: netstat -an | findstr 19283
3. Verify config: luna_daemon/config.py has correct DAEMON_HOST/PORT
4. Try force_local mode in Model Router to bypass daemon
```

### LoRA Weights Not Resetting
```
Issue: Model still has LoRA effects after Reset Weights node

Solutions:
1. Verify Reset Weights node is connected and executed
2. Check that same model is used in Config Gateway and Reset node
3. Clear cache manually: restart ComfyUI
4. Ensure Config Gateway ran before Reset (check workflow order)
```

### Precision Conversion Failed
```
Error: "Failed to convert model to fp8"

Solutions:
1. Check CUDA version supports fp8 (Ampere/Ada/Blackwell)
2. Verify disk space in models/unet/fp8/ directory
3. Check write permissions
4. Try bf16 instead (more compatible)
```

### Out of Memory with Multiple Workflows
```
Error: CUDA OOM when running 3+ instances

Solutions:
1. Reduce worker pool size in daemon config
2. Use fp8/GGUF precision to reduce VRAM per model
3. Enable InferenceModeWrapper offloading
4. Increase VRAM or reduce concurrent instances
```

---

## ğŸ¤ Contributing

Contributions welcome! Please:
1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“œ License

MIT License - see LICENSE file for details

---

## ğŸ™ Acknowledgments

- ComfyUI team for the excellent framework
- Community contributors for feedback and testing
- Open source projects that inspired Luna's architecture

---

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/LSDJesus/ComfyUI-Luna-Collection/issues)
- **Discussions**: [GitHub Discussions](https://github.com/LSDJesus/ComfyUI-Luna-Collection/discussions)
- **Documentation**: See `Docs/` directory for detailed technical documentation

| Node | Description |
|------|-------------|
| **Luna Z-IMAGE Encoder ğŸ§ ** | AI-enhanced encoding with Qwen3-VL, vision modes, noise injection |
| **Luna Vision Node ğŸ‘ï¸** | Describe/extract style from reference images |
| **Luna VLM Prompt Generator ğŸ’¬** | Generate prompts from images using vision LLM |
| **Luna Prompt List Loader** | Load prompts from CSV/JSON/YAML files |
| **Luna Batch Prompt Extractor** | Extract prompts from image EXIF metadata |
| **Luna Config Gateway** | Centralized workflow parameters |
| **Luna Trigger Injector** | Auto-inject LoRA trigger words |
| **Luna Expression Pack** | Logic and math expressions for workflows |

**Luna Z-IMAGE Encoder** - Unified prompt processing for Z-IMAGE models:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Luna Z-IMAGE Encoder ğŸ§                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  PROMPT:        "anime girl, detailed, colorful"                           â”‚
â”‚  AI ENHANCEMENT: [off] [subtle] [moderate] [maximum]                       â”‚
â”‚                                                                             â”‚
â”‚  VISION MODE:   [disabled] [describe] [extract_style] [blend]              â”‚
â”‚  IMAGE INPUT:   [optional reference image]                                 â”‚
â”‚                                                                             â”‚
â”‚  NOISE INJECTION: [âœ“ Enable] strength: 0.02  schedule: start_percent: 0.3  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  OUTPUTS: CONDITIONING (with style/noise), enhanced_prompt                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Vision Modes:**
| Mode | Description | Best For |
|------|-------------|----------|
| `disabled` | Text-only encoding | Pure text2img |
| `describe` | VLM describes image â†’ expands prompt | Character/scene reference |
| `extract_style` | Extract artistic style â†’ inject as suffix | Style transfer |
| `blend` | Fuse text + image embeddings (0.0-1.0) | Image variations |

**Luna Prompt List Loader** outputs:
- `positive` - Positive prompt string
- `negative` - Negative prompt string  
- `seed` - Per-prompt seed (or -1 for random)
- `lora_stack` - LoRA stack tuple for Apply LoRA Stack
- `index` - Current iteration index

### ğŸ“ **LoRA & Embedding Management**

| Node | Description |
|------|-------------|
| **Luna LoRA Stacker** | Stack up to 4 LoRAs with strength controls |
| **Luna LoRA Stacker Random** | Randomized LoRA selection |
| **Luna Embedding Manager** | Textual inversion management |
| **Luna Embedding Manager Random** | Randomized embedding selection |
| **Luna LoRA Validator** | Validate LoRA files and extract metadata |
| **Luna Connections Manager** | Sidebar UI for LoRA/embedding â†” wildcard linking |

### ğŸ–¼ï¸ **Image Processing**

| Node | Description |
|------|-------------|
| **Luna Simple Upscaler** | Clean model-based upscaling |
| **Luna Advanced Upscaler** | Supersampling, modulus rounding |
| **Luna Ultimate SD Upscale** | Tile-based SD upscaling |
| **Luna Batch Upscale Refine** | âš¡ NEW: Chess-pattern tiling with scaffolding noise (v2.1) |
| **Luna Super Upscaler âš¡** | SeedVR2-powered mega-resolution upscaling (3B/7B DiT models) |
| **Luna Super Upscaler (Simple)** | Streamlined version with minimal inputs |
| **Luna Multi Saver** | Batch saving with templates |

**Luna Batch Upscale Refine** (NEW in v2.1):
- **Scaffolding Noise**: Preserves original noise structure to prevent hallucinations
- **Chess Pattern Batching**: 2-pass refinement with automatic seam healing
- **Auto-Grid**: Grid size = Upscale Factor + 1 (e.g., 4x upscaler â†’ 5x5 grid)
- **Sigmoid Blending**: Smooth S-curve blending with feathering control  
- **GPU Lanczos**: Supersampling downscale (e.g., refine at 4x, output at 2x)
- **Tiled VAE**: Seamless decoding prevents boundary artifacts
- **VRAM Optimized**: ~4-5GB for RTX 5090 vs 7-8GB traditional upscalers

> **Note:** Luna Super Upscaler requires [SeedVR2](https://github.com/Seed-VR/SeedVR2-Video-Upscaler-ComfyUI) as a dependency. Install it separately in your `custom_nodes/` folder.

### ğŸ”§ **Utilities**

| Node | Description |
|------|-------------|
| **Luna Civitai Metadata Scraper** | Fetch LoRA metadata from Civitai |
| **Luna Expression Pack** | Logic and math expressions |
| **Luna Dimension Scaler** | Scale to model-native resolutions |

---

## ğŸ”— External Tool Integration

### Realtime LoRA Training (comfyUI-Realtime-Lora)

Luna Collection is designed to work seamlessly with [comfyUI-Realtime-Lora](https://github.com/shootthesound/comfyUI-Realtime-Lora) for in-workflow SDXL LoRA training:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 REALTIME LORA TRAINING WORKFLOW                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Luna Batch Prompt    â”‚â”€â”€â”€â”€â–¶â”‚ images_path folder with .txt captionsâ”‚
  â”‚ Extractor (export)   â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
                                                  â–¼
                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                               â”‚ Realtime LoRA Trainer (SDXL)         â”‚
                               â”‚ â€¢ sd_scripts_path: D:/AI/.../sd-scripts
                               â”‚ â€¢ ckpt_name: illustrious_v1.safetensors
                               â”‚ â€¢ Uses kohya sd-scripts                â”‚
                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                  â”‚ lora_path
                                                  â–¼
                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                               â”‚ Apply Trained LoRA                   â”‚
                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                  â”‚
                                                  â–¼
                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                               â”‚ KSampler (generate with new LoRA)    â”‚
                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Setup:** Create a junction so sd-scripts can use ComfyUI's venv:
```powershell
New-Item -ItemType Junction -Path "D:\path\to\sd-scripts\.venv" -Target "D:\AI\ComfyUI\venv"
```

### DiffusionToolkit Bridge (Planned)

See [docs/LUNA_TOOLKIT_BRIDGE_NODES.md](docs/LUNA_TOOLKIT_BRIDGE_NODES.md) for planned integration nodes that enable:
- Query DT image library from ComfyUI
- Similar image search via embeddings
- Cluster-based sampling
- Caption fetching
- Metadata writeback

---

## ğŸ“š Technical Deep Dives

### Luna Daemon Protocol

**Length-Prefix Protocol (v1.3):**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4-byte uint32    â”‚ JSON payload (exact length)     â”‚
â”‚ payload length   â”‚                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Replaces the old `<<END>>` sentinel pattern which required O(nÂ²) string scanning.

**F-150 LoRA Architecture:**
```python
# TransientLoRAContext - thread-safe LoRA injection
with TransientLoRAContext(clip_model, lora_stack, registry):
    # 1. Lock acquired
    # 2. LoRA weights loaded from registry (LRU cached)
    # 3. Weights injected via add_patches()
    # 4. Encode happens here
    # 5. Weights restored on exit
    # 6. Lock released
```

### Dynamic Loader Smart Evaluation

The loader uses ComfyUI's `check_lazy_status` to detect connected outputs:

```python
def check_lazy_status(self, ckpt_name, precision, ...):
    # Always need MODEL and unet_path
    needed = [0, 3]
    
    # Check graph for CLIP/VAE connections
    if self._is_output_connected(graph, node_id, 1):  # CLIP
        needed.append(1)
    if self._is_output_connected(graph, node_id, 2):  # VAE
        needed.append(2)
    
    return needed
```

This means:
- **MODEL only connected**: Just loads optimized UNet (~2-4GB)
- **MODEL + CLIP**: Loads UNet + extracts CLIP from source
- **MODEL + VAE**: Loads UNet + extracts VAE from source
- **All connected**: Full hybrid load

### CUDA IPC Zero-Copy

When VAE daemon runs on the same GPU as ComfyUI:

```python
# Client side
tensor.share_memory_()  # Move to shared memory
handle = tensor.storage()._share_cuda_()

# Send handle via socket (tiny metadata, not tensor data)
response = send_ipc_request(handle, shape, dtype)

# Server side - reconstructs tensor from handle
tensor = torch.zeros(shape, dtype=dtype, device=device)
tensor.storage()._set_from_cuda_ipc_handle_(handle)
```

Result: 13 VAE operations per iteration with zero serialization overhead.

---

## ğŸ—ï¸ Project Structure

```
ComfyUI-Luna-Collection/
â”œâ”€â”€ nodes/                          # Node implementations
â”‚   â”œâ”€â”€ loaders/                    # Model loading nodes
â”‚   â”‚   â”œâ”€â”€ luna_model_router.py    # Unified multi-architecture loader
â”‚   â”‚   â”œâ”€â”€ luna_secondary_loader.py # Multi-model + RAM offload
â”‚   â”‚   â”œâ”€â”€ luna_dynamic_loader.py  # JIT precision conversion
â”‚   â”‚   â””â”€â”€ luna_checkpoint_tunnel.py
â”‚   â”œâ”€â”€ promptcraft/                # Prompt engineering nodes
â”‚   â”‚   â”œâ”€â”€ engine.py               # YAML parser engine
â”‚   â”‚   â””â”€â”€ nodes.py                # Wildcard nodes
â”‚   â”œâ”€â”€ upscaling/                  # Upscaler nodes
â”‚   â”œâ”€â”€ luna_zimage_encoder.py      # Z-IMAGE AI encoder + vision
â”‚   â”œâ”€â”€ luna_vision_node.py         # VLM-based image analysis
â”‚   â”œâ”€â”€ luna_vlm_prompt_generator.py # Vision â†’ prompt
â”‚   â”œâ”€â”€ luna_yaml_wildcard.py       # YAML wildcard system
â”‚   â”œâ”€â”€ luna_batch_prompt_extractor.py
â”‚   â”œâ”€â”€ luna_config_gateway.py
â”‚   â”œâ”€â”€ luna_multi_saver.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ luna_daemon/                    # Multi-instance daemon
â”‚   â”œâ”€â”€ server.py                   # Daemon server (dynamic scaling)
â”‚   â”œâ”€â”€ client.py                   # Client library
â”‚   â”œâ”€â”€ proxy.py                    # DaemonVAE/DaemonCLIP proxies
â”‚   â””â”€â”€ config.py                   # Configuration
â”œâ”€â”€ utils/                          # Shared utilities
â”‚   â”œâ”€â”€ luna_metadata_db.py         # SQLite metadata
â”‚   â””â”€â”€ ...
â”œâ”€â”€ js/                             # Frontend JavaScript
â”œâ”€â”€ tests/                          # Test suite
â””â”€â”€ __init__.py
```

---

## ğŸ”§ Configuration

### Daemon Configuration (`luna_daemon/config.py`)

```python
# Service type for split architecture
class ServiceType(Enum):
    FULL = "full"           # CLIP + VAE on same GPU
    CLIP_ONLY = "clip"      # CLIP daemon only
    VAE_ONLY = "vae"        # VAE daemon only

# Network
DAEMON_HOST = "127.0.0.1"
DAEMON_PORT = 19283         # CLIP daemon
DAEMON_VAE_PORT = 19284     # VAE daemon (split mode)

# GPU Assignment
SHARED_DEVICE = "cuda:1"    # For CLIP
VAE_DEVICE = "cuda:0"       # For VAE (same as UNet = IPC eligible)

# Model Paths
VAE_PATH = "models/vae/sdxl_vae.safetensors"
CLIP_L_PATH = "models/clip/clip_l.safetensors"
CLIP_G_PATH = "models/clip/clip_g.safetensors"

# LoRA Cache
LORA_CACHE_MAX_SIZE = 2 * 1024 * 1024 * 1024  # 2GB LRU
```

### Dynamic Loader Configuration

The loader stores optimized UNets in `models/unet/optimized/` by default.
Override with the `local_weights_dir` input.

---

## ğŸ“ˆ Changelog

### v1.5.0 - Current (2025-06)
- âœ… **Luna Model Router**: Unified loader for ALL architectures (SD1.5/SDXL/Flux/SD3/Z-IMAGE) with explicit 4-slot CLIP configuration
- âœ… **Luna Secondary Model Loader**: Multi-model workflows with CLIP sharing and RAM offloading via ModelMemoryManager
- âœ… **Luna Model Restore**: Companion node to restore RAM-offloaded models back to VRAM
- âœ… **Luna Z-IMAGE Encoder**: AI-enhanced prompt encoding with Qwen3-VL, vision modes (describe/extract_style/blend), built-in noise injection
- âœ… **Luna Vision Node**: Describe images or extract artistic style using VLM
- âœ… **Luna VLM Prompt Generator**: Generate prompts from reference images
- âœ… **Auto-Discovery Node Registration**: `os.walk()` based node discovery from subdirectories
- âœ… **LLM Output Support**: Model Router outputs LLM for Z-IMAGE (Qwen3-VL) workflows
- âœ… **CLIP_VISION Output**: Direct CLIP vision model output for vision-enabled architectures

### v1.4.0 (2025-12)
- âœ… **Connections Manager Sidebar**: LoRA/embedding â†” wildcard category linking UI
- âœ… **PromptCraft Engine**: Intelligent prompt generation with constraints/modifiers/expanders
- âœ… **DynamicPrompt API Update**: Fixed compatibility with latest ComfyUI graph API
- âœ… **Realtime LoRA Training Integration**: Documentation for sd-scripts integration
- âœ… **DiffusionToolkit Bridge Spec**: Planned nodes for DT â†” ComfyUI communication
- âœ… **Expression Pack**: Logic and math expression nodes
- âœ… **Trigger Injector**: Auto-inject LoRA trigger words into prompts

### v1.3.0 (2025-12)
- âœ… **Split Daemon Architecture**: Separate CLIP/VAE daemons for optimal GPU placement
- âœ… **CUDA IPC**: Zero-copy tensor transfer for same-GPU VAE operations
- âœ… **F-150 LoRA**: Transient LoRA injection for shared CLIP with LRU cache
- âœ… **Length-Prefix Protocol**: O(n) transport replacing O(nÂ²) sentinel scanning
- âœ… **Luna Dynamic Model Loader**: JIT precision conversion with smart lazy evaluation
- âœ… **Smart Output Detection**: CLIP/VAE only load when outputs are connected
- âœ… **Hybrid Loading**: CLIP/VAE from FP16 source + optimized UNet from NVMe
- âœ… **GGUF Support**: Q8_0 and Q4_K_M quantization for Ampere/Blackwell

### v1.2.0 (2025-11-29)
- âœ… **YAML Wildcard System**: Hierarchical wildcards with templates
- âœ… **Luna Daemon**: Multi-instance VRAM sharing
- âœ… **Civitai Integration**: Automatic metadata scraping
- âœ… **SQLite Metadata Database**: Local storage with full-text search
- âœ… **Batch Prompt Extractor**: EXIF parsing with UTF-16BE support

### v1.1.0 (2025-09-21)
- âœ… **TensorRT Integration**: High-performance detailing
- âœ… **Enhanced LoRA Stacker**: Individual toggles, proper tuple format

### v1.0.0 (2025-08-22)
- ğŸ¯ Initial release with upscalers, LoRA management, prompt processing

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details.

---

*Built with â¤ï¸ for high-throughput image generation*

